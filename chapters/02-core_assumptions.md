# 2 Relaxing the Core FL Assumptions

在本节中，我们将讨论与上一节中讨论的主题相关的研究领域。即使不是本文其余部分的主要重点，在这些领域的进步也可能会激发下一代生产系统的设计。

## 2.1 完全去中心化/点对点的分布式学习

在联邦学习中，中央服务器负责协调训练过程并接收所有客户的贡献。因此，服务器是中央播活跃装置，它也可能表现单点故障。尽管大型公司或组织可以在某些应用场景中扮演这个角色，但是在更多协作学习场景中，可靠，强大的中央服务器可能并不总是可用或理想的\[392]。此外，如Lian等人\[266]所述，当客户端数量很大时，服务器甚至可能成为瓶颈。 (尽管可以通过精心设计的系统来减轻这种情况，例如\[74])。

完全去中心化学习的关键思想是通过单个客户端之间的对等通信来代替与服务器的通信。通信拓扑表示为连接图，其中节点是客户端，边表示两个客户端之间的通信通道。通常将网络图选择为具有最小中最大程度的稀疏图，以便每个节点仅需要向/从少量对等点发送/接收消息。这与服务器-客户端体系结构的星形图相反。在完全去中心化的算法中，每个客户对应一个回合本地更新并与图中的邻居交换信息（但是请注意，在这种情况下，轮次的概念甚至不需要，参见\[78]中有关时钟模型的讨论）。在机器的背景下，在学习过程中，本地更新通常是本地（随机）梯度步骤，而交流则包括与邻居平均一个本地模型参数。请注意，不再像标准联邦学习中那样存在模型的全局状态，而是可以设计该过程，以使所有局部模型收敛到所需的全局解决方案，即各个模型逐渐达成共识。尽管多主体优化在控制领域有着悠久的历史，但最近在机器学习中已经考虑了SGD的完全去中心化变体和其他优化算法，以提高数据中心的可伸缩性\[30]以及设备的去中心化网络\[110]。 392、379、54、243、253、153]。他们还考虑了无向网络图，尽管在\[30，200]中也研究了有向网络（编码在现实世界中可能出现的单向通道，例如社交网络或数据市场）的情况。

值得注意的是，即使在上述去中心化的环境中，中央机构仍可能负责建立学习任务。例如，考虑以下问题：谁决定在去中心化环境中训练什么模型？使用什么算法？什么超参数？当某些东西无法按预期工作时，谁负责调试？回答这些问题仍然需要中央机构中参与客户的一定程度的信任。或者，可以由提出学习任务的客户来决定，也可以通过共识计划来共同做出决定（请参阅第2.1.2节）。

表3比较了联邦学习和P2P学习。尽管去中心化学习的架构假设与联邦式学习的假设不同，但它通常可以应用于相似的问题领域，出现许多相同的挑战，并且在研究领域存在很多重叠之处。因此，我们也考虑在本文中进行去中心化学习。在这一部分的挑战中明确考虑了去中心化方法特定的问题，但其他部分中的许多未解决问题也出现在去中心化情况下。

|      | 联邦学习                                   | 完全去中心化（点对点）学习 |
| ---- | -------------------------------------- | ------------- |
| 编排方式 | 中央编排流程服务器或服务负责组织训练，但从未看到原始数据。          | 没有集中的编排流程。    |
| 宽域通信 | 中心辐射型拓扑，中心代表协调服务提供商（通常不包含数据），分支连接到客户端。 | 对等拓扑，带有动态连接图。 |

> 表3：联邦学习和完全去中心化学习之间主要区别的比较。请注意，与FL一样，去中心化学习可以进一步划分为不同的用例，其区别类似于表1中比较跨数据孤岛FL和跨设备FL的区别。

### 2.1.1 算法挑战

关于机器学习的去中心化方案在现实世界中的可用性，仍然存在大量重要的算法问题。有些问题类似于使用中央服务器的联邦学习的特殊情况，而其他挑战则来自完全去中心化或不信任的附加副作用。我们在下面概述了一些特定领域。

**网络拓扑和异步对去中心化SGD的影响** 完全去中心化学习算法应对客户端的有限可用性（客户端暂时不可用，在执行过程中退出或加入）和网络的有限可靠性（可能存在消息丢弃）具有鲁棒性。虽然对于广义线性模型的特殊情况，使用对偶结构的方案可以实现其中一些所需的鲁棒性\[201]，但对于深度学习和SGD而言，这仍然是一个悬而未决的问题。当网络图完成但消息具有固定的概率被丢弃时，Yu等人 \[427]表明，一个人可以达到与可靠网络情况相当的收敛速度。其他开放式研究问题涉及非IID数据分布，更新频率，有效的通信模式和实际收敛时间\[379]，我们将在下面更详细地概述。

连接良好或密集的网络可以促进更快的共识，并提供更好的错误收敛速度（取决于网络图的频谱间隙），但它们会导致通信延迟，并随节点的度数而增加。大多数优化理论的工作都没有明确考虑拓扑如何影响运行时间，即完成每个SGD迭代所需的时间。 Wang等 \[401]提出了MATCHA，这是一种基于匹配分解采样的去中心化的SGD方法，它在保持相同的错误收敛速度的同时，减少了任何给定节点拓扑的每次迭代的通信延迟。关键思想是将图拓扑分解为可并行运行的不相交通信链路组成的匹配，并在每次迭代中仔细选择这些匹配的子集。此子图序列进而通过连通性至关重要的链接进行更频繁的通信（确保快速的错误收敛），而在其他链接上进行的通信较少（保存了通信延迟）。

去中心化SGD的条件自然也很适合异步算法，其中每个客户端在随机时间独立活动，从而消除了对全局同步的需求，并潜在地提高了可伸缩性\[110、392、54、30、267]。

**本地更新去中心化SGD** 与小批量SGD中的使用单个SGD步骤的方案相比，在通信回合之前执行几个本地更新步骤的方案的理论分析更具挑战性。尽管稍后将在第3.2节中对此进行讨论，但在这里完全去中心化的利益环境中，也同样适用。在非IID本地数据集的情况下，通常证明依赖单个本地更新步骤的方案可以收敛\[243，242]。 Wang和Joshi \[399]最近提供了具有几个本地更新步骤的案例的收敛性分析。此外，\[401]针对非IID数据情况，但是针对基于上述匹配分解采样的特定方案，提供了收敛分析。但是，总的来说，了解非IID数据分布下的收敛性以及如何设计实现最快收敛性的模型平均策略仍然是一个悬而未决的问题。

**个性化和信任机制** 与跨设备FL设置类似，对于单个客户端可用的非IID数据分布下的完全去中心化方案，一项重要任务是设计用于学习个性化模型集合的算法。 \[392，54]的工作引入了完全去中心化的算法，以通过在具有相似任务（即相似数据分布）的客户端之间平滑模型参数，从而为每个客户端协作学习个性化模型。 Zantedeschi等。 \[431]进一步学习相似度图和个性化模型。在去中心化环境中，关键的独特挑战之一仍然是这种方案对恶意行为者的鲁棒性或对不可靠数据或标签的贡献。激励或机制设计与去中心化学习相结合的使用是一个新兴且重要的目标，如果没有受信任的中央服务器，在环境中可能很难实现。

**梯度压缩和量化方法** 在潜在的应用中，客户端通常会受到可用的通信带宽和允许的能源使用方面的限制。在不对融合产生负面影响的情况下，将一些现有的压缩通信方案从集中协调器促进的设置转换为通用和完全去中心化的设置是一个当前活跃的研究方向\[243、335、380、242]。一个补充的想法是设计去中心化的优化算法，该算法自然会导致稀疏更新\[431]。

**隐私** 在完全去中心化的学习中，一个重要的挑战是防止任何客户端从其共享的更新中重建另一个客户端的私人数据，同时保持对所学模型的良好效用水平。<mark style="background-color:orange;">差分隐私（见第4节）是缓解这种隐私风险的标准方法。在去中心化的联邦学习中，这可以通过让每个客户端在本地添加噪声来实现，如\[239, 59]。不幸的是，这样的局部隐私方法往往要付出很大的效用代价。</mark><mark style="background-color:green;">此外，基于安全聚合或安全洗牌的分布式方法，旨在改善标准FL设置中的隐私和效用权衡（见第4.4.3节），不容易与完全去中心化的算法整合。在完全去中心化的算法中实现隐私和效用之间更好的权衡的一个可能的方向是依靠去中心化本身来放大差分隐私保证，例如通过考虑适当地应用放松的局部差分隐私\[146]。</mark>

### 2.1.2 实际挑战

完全去中心化学习的一个正交问题是如何在实践中实现它。本节概述了基于分布式账本的思想的一系列相关想法。

区块链是在不同用户之间共享的分布式账本，无需中央授权即可进行数字交易，包括加密货币交易。特别是，智能合约允许在区块链之上执行任意代码，而区块链本质上是一个大规模复制的最终一致的状态机。在联邦学习方面，该技术的使用可以通过使用智能合约进行模型聚合来实现全球服务器的去中心化，其中执行智能合约的参与客户端可以是不同的公司或云服务。

但是，在Ethereum\[409]等当今的区块链平台上，默认情况下可以公开获取区块链上的数据，这可能会阻止用户参与去中心化联邦学习协议，因为数据的保护通常是FL的主要动机。为了解决此类问题，可能会修改现有的隐私保护技术以适应去中心化联邦学习的情况。首先，为了防止参与节点利用单独提交的模型更新，可以使用现有的安全聚合协议。 <mark style="background-color:blue;">Bonawitz等人提出了一种已在跨设备FL中使用的实用的安全聚集协议。 \[73]，以协议的复杂性为代价，有效地处理了退出的参与者。另一种系统是让每个客户在区块链上存入加密货币存款，如果他们在执行过程中退出则受到惩罚。无需处理丢失，可以显着简化安全聚合协议。实现安全聚合的另一种方法是使用机密智能合约，例如在安全区域内运行的Oasis协议\[104]所启用的合约。这样，每个客户端可以简单地提交一个加密的本地模型更新，知道模型将被解密，并通过远程验证在安全硬件内进行汇总（当然，见第4.1节中关于深入隐私的讨论）。</mark>

<mark style="background-color:orange;">为了防止任何客户端试图通过利用全局模型来重建另一客户端的私有数据，已经针对FL提出了客户端级别的差分隐私\[290]。通过在聚合的全局模型上添加足以隐藏任何单个客户端的更新的随机高斯噪声，可以实现客户端级别的差分隐私。在去中心化联邦学习的情况下，我们也可以让每个客户端在本地添加噪音，如\[54]中所述。也就是说，每个客户端在局部梯度下降步骤之后在本地添加一定量的高斯噪声，并将模型提交给区块链。计算本地添加的噪声等级，以便区块链上的聚合噪声能够实现与\[290]中相同的客户端级别的差分隐私。最后，可以对区块链上的汇总全局模型进行加密，并且只有参与的客户端才拥有解密密钥，从而保护了模型不受公众攻击。</mark>

## 2.2 跨数据孤岛的联邦学习

与跨数据孤岛的联邦学习的特征相反，请参见表1，跨数据孤岛的联邦学习在整体设计的某些方面承认了更大的灵活性，但同时也提供了难以实现其他性能的设置。本节讨论其中一些差异。

<mark style="background-color:blue;">如果许多公司或组织共享激励以基于其所有数据来训练模型，但不能直接共享其数据，则跨数据孤岛可能是相关的。这可能是由于机密性的限制或法律的限制，甚至是在一家公司无法将数据集中在不同地理区域之间时，甚至在一家公司内部。这些跨数据孤岛应用引起了广泛的关注。</mark>

**数据分割** 在跨数据孤岛设置中，数据将通过示例（examples）进行分区。在跨数据孤岛中，除了按示例进行分区之外，按特征进行分区也具有实际意义。例如，当不同业务的两家公司拥有相同或重叠的客户集时，例如同一城市中的本地银行和本地零售公司。 Yang等人也将此差异称为纵向和横向联邦学习\[419]。

与按特征划分数据的设置相比，具有跨数据孤岛的FL采用了非常不同的训练架构，即按示例划分数据。它可能包含或不包含中央服务器，并且根据训练算法的具体情况，客户交换特定的中间结果而不是模型参数，以帮助其他方进行梯度计算。参见例如\[419，第2.4.2节]。<mark style="background-color:blue;">在此设置中，应用安全多方计算或同态加密等技术被提出，这是为了限制其他参与者从训练过程中可以推断出的信息量。</mark>这种方法的缺点是训练算法通常取决于所追求的机器学习目标的类型。当前提出的算法包括树\[103]，线性和逻辑回归\[419、198]和神经网络\[276]。

联邦迁移学习\[419]是另一个具有挑战性的概念，其中数据各方仅在用户空间或特征空间中共享部分重叠，并利用现有的迁移学习技术\[314]来协作构建模型。现有的公式仅限于2个客户的情况。

当单个公司由于法律约束而无法集中数据时，或者当目标相似的组织希望通过协作来改进其模型时，按示例进行分区通常与跨数据孤岛FL相关。例如，不同的银行可以合作训练分类或异常检测模型以进行欺诈检测\[407]，医院可以构建更好的诊断模型\[121]，依此类推。

支持上述应用程序的开源平台目前可以作为_联邦AI技术使能器（FATE使用_\[34]。同时，IEEE P3652.1联邦机器学习工作组专注于联邦AI技术框架的标准制定。

**激励机制** 除了为FL开发新的算法技术之外，诚实参与的激励机制设计也是一个重要的实践研究问题。这种需求可能会出现在跨设备设置中（例如\[225，224]），但在跨孤岛设置中尤其重要，因为参与者也可能是企业竞争对手。相关目标包括如何将联邦学习模型产生的收益分配给贡献数据的所有者，以维持长期参与，以及如何将激励措施与防御对抗性数据所有者的决策联系起来，以增强系统安全性，优化参与者的参与度。数据所有者，以提高系统效率。

**差分隐私** 第4.1节中有关参与者和威胁模型的讨论也与跨孤岛FL密切相关。但是，防范不同行为者可能具有不同的优先级。例如，在许多实际情况下，最终的训练模型将仅发布给参加训练的人员，这使得对“世界其他地区”的担忧变得不那么重要了。

另一方面，对于具有说服力的主张，我们通常需要本地差分隐私的概念，因为来自其他客户的潜在威胁可能更加重要。在客户端不被视为重大威胁的情况下，每个客户端都可以控制来自其各自用户的数据，因此可能需要在此类用户级别上提供正式的隐私保证。根据应用，其他目标可能值得追求。但该领域尚未得到系统地探索。

**张量分解** 一些工作还研究了跨孤岛联合张量分解，其中多个站点（每个站点都有一组具有相同特征的数据，即水平分区）通过仅与协调服务器共享中间因子同时保持数据私密性来共同执行张量分解。每个站点。<mark style="background-color:orange;">在现有工作中，\[236]使用了基于乘数的交替方向方法（ADMM），\[280]通过弹性平均SGD（EASGD）算法提高了效率，并进一步确保了中间因素的差分隐私。</mark>

## 2.3 拆分学习

与之前的着重于数据分区和通信模式的设置相比，拆分学习\[190，393] 背后的关键思想是在客户端和服务器之间按层划分模型的执行（请参照拆分学习项目网站-https://splitlearning.github.io/）。对于训练和推理都可以做到这一点。

在拆分学习的最简单配置中，每个客户端都会计算通过深度网络的前向传播，直到到达称为切割层的特定层。剪切层的输出（称为粉碎数据）被发送到另一个实体（服务器或另一个客户端），这将完成其余的计算。这样就完成了一轮向前传播，而无需共享原始数据。然后可以按照类似的方式从最后一层向后传播梯度直到剪切层。剪切层上的渐变（仅这些渐变）被发送回客户端，其余的反向传播完成。这个过程一直持续到收敛为止，而不必让客户端直接彼此访问原始数据。此设置如图2（a）所示，该设置的一种变体如图2（b）所示，其中标签也没有与原始数据一起共享。

![图2: 在原始设置中，不会显示原始数据的拆分学习配置，在U形拆分学习设置中，原始数据和标签不会在客户端和服务器实体之间传输。](../images/chapter01/split\_learning.png)

在\[360]中比较了拆分学习和联邦学习的总体交流需求。拆分学习在训练中带来了并行性的另一个方面，即模型各部分之间的并行化。客户端和服务器。在\[213，207]中，作者打破了部分网络之间的依赖关系，并通过并行化不同部分中的计算来减少总的集中训练时间，这一点在这里也可能是相关的。然而，在边缘设备上探索拆分学习的这种并行化仍然是一个悬而未决的问题。拆分学习还可以将客户端模型组件与最佳服务器端模型组件进行匹配，以自动进行模型选择，如ExpertMatcher \[353]所示。

但是，所传达的值通常可以揭示有关基础数据的信息。多少以及是否可以接受，将取决于应用程序和配置。拆分学习的一种变体称为NoPeek SplitNN \[395]，它通过减少与原始数据之间的距离相关性\[394，378]，从而通过通信活动减少了潜在的泄漏，同时通过分类交叉熵保持了良好的模型性能。关键思想是最小化原始数据点和通信的粉碎数据之间的距离相关性。如果不使用NoPeek SplitNN，则所传达的对象可能包含与输入数据高度相关的信息，这个用途也可以根据给定的解相关性相对较早地进行拆分。第4节中的许多讨论在这里也很重要，并且提供专门针对拆分学习的正式隐私保证的分析仍然是一个开放问题。
